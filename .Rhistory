demo()
myvar<-"hello"
myvar
class(myvar)
dataset <- read.delim("C:/Users/Sudip P/Desktop/dataset.txt")
View(dataset)
data<-{1:10}
data
var<-"abcd"
var
var bcd
var="bcd"
var
var=3
var=56786
var1=56786
da=var+var1
da
var=c(5,2)
var
da=var[1]*var[0]
da
5*2
da=c[0]*c[1]
var=[1,2]
rm(da)
echo hello
print("hello")
print(hello)
var=10
var
res=var*10
res
help("vector")
rm(res)
rm(var)
quit
q()
help(translate)
help(translat)
conditional_prob <- read.csv("C:/Users/Sudip P/Desktop/Misc/Karuna/conditional_prob.csv")
View(conditional_prob)
conditional_prob
conditional_prob.search
search(conditional_prob.about)
ls
ps
cal
cal
date
View(conditional_prob)
install.packages("weka")
install.packages("twitteR")
install.packages("tm")
install.packages("tm")
install.packages("wordcloud")
install.packages("wordnet")
install.packages("PythonInR")
install.packages("PredictiveRegression")
install.packages("bigdata")
library(twitteR)
> # retrieve the first 200 tweets (or all tweets if fewer than 200) from the
> # user timeline of @rdatammining
> rdmTweets <- userTimeline("rdatamining", n=200)
> (nDocs <- length(rdmTweets))
library(twitteR)
# retrieve the first 200 tweets (or all tweets if fewer than 200) from the
# user timeline of @rdatammining
rdmTweets <- userTimeline("rdatamining", n=200)
getTwitterOAuth(	omivSrJDPQvR1T6f7UNxUG3me,YGAO1fAKeT2EixZCxYQHaXFaaTuqOva4URWXVE9K8F7vj3uC2n)
?setup_twitter_oauth
setup_twitter_oauth(omivSrJDPQvR1T6f7UNxUG3me,YGAO1fAKeT2EixZCxYQHaXFaaTuqOva4URWXVE9K8F7vj3uC2n, 2305131019-GfHwNZfUsCXikPHLRgKcvB2INEqRkFRHHunTpAc, 9qIhiYiQnvEKIQKbLvFEi2asyquh1WA6nzi6TJa6clFEK
)
setup_twitter_oauth(omivSrJDPQvR1T6f7UNxUG3me,YGAO1fAKeT2EixZCxYQHaXFaaTuqOva4URWXVE9K8F7vj3uC2n,2305131019-GfHwNZfUsCXikPHLRgKcvB2INEqRkFRHHunTpAc,9qIhiYiQnvEKIQKbLvFEi2asyquh1WA6nzi6TJa6clFEK)
setup_twitter_oauth(omivSrJDPQvR1T6f7UNxUG3me,YGAO1fAKeT2EixZCxYQHaXFaaTuqOva4URWXVE9K8F7vj3uC2n, 2305131019-GfHwNZfUsCXikPHLRgKcvB2INEqRkFRHHunTpAc,9qIhiYiQnvEKIQKbLvFEi2asyquh1WA6nzi6TJa6clFEK)
setup_twitter_oauth(omivSrJDPQvR1T6f7UNxUG3me,YGAO1fAKeT2EixZCxYQHaXFaaTuqOva4URWXVE9K8F7vj3uC2n, 2305131019-GfHwNZfUsCXikPHLRgKcvB2INEqRkFRHHunTpAc,9qIhiYiQnvEKIQKbLvFEi2asyquh1WA6nzi6TJa6clFEK
setup_twitter_oauth(omivSrJDPQvR1T6f7UNxUG3me, YGAO1fAKeT2EixZCxYQHaXFaaTuqOva4URWXVE9K8F7vj3uC2n, access_token=NULL, access_secret=NULL)
setup_twitter_oauth(omivSrJDPQvR1T6f7UNxUG3me, YGAO1fAKeT2EixZCxYQHaXFaaTuqOva4URWXVE9K8F7vj3uC2n, GfHwNZfUsCXikPHLRgKcvB2INEqRkFRHHunTpAc, 9qIhiYiQnvEKIQKbLvFEi2asyquh1WA6nzi6TJa6clFEK)
library(twitteR)
# retrieve the first 200 tweets (or all tweets if fewer than 200) from the
# user timeline of @rdatammining
rdmTweets <- userTimeline("rdatamining", n=200)
update.packages(ask='graphics',checkBuilt=TRUE)
q()
install.packages("shiny")
install.packages("RCurl")
require(twitteR)
require(RCurl)
consumer_key<-'AIoVwQzG4XEbqdTqszKv5ZdvM'
consumer_secret<-'eG6tosZmpVSpTPcc9lkUFMVGNwjPyUCNnAqvb9wVLfpQ2e6eus'
View(conditional_prob)
View(conditional_prob)
consumer_key<-'AIoVwQzG4XEbqdTqszKv5ZdvM'
consumer_secret<-'eG6tosZmpVSpTPcc9lkUFMVGNwjPyUCNnAqvb9wVLfpQ2e6eus'
access_token<-'	2305131019-A0rt8nbK87x1nNBne8zKAthlH2hYwPU2FejMVED'
access_secret<-'XfBzYxzeyZuwjggK7HpRZjxfZCQijDDnKGv3VUU6xs32a'
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
access_token<-'2305131019-A0rt8nbK87x1nNBne8zKAthlH2hYwPU2FejMVED'
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
consumer_key<-'omivSrJDPQvR1T6f7UNxUG3me'
consumer_secret<-'YGAO1fAKeT2EixZCxYQHaXFaaTuqOva4URWXVE9K8F7vj3uC2n'
access_token<-'2305131019-GfHwNZfUsCXikPHLRgKcvB2INEqRkFRHHunTpAc'
access_secret<-'9qIhiYiQnvEKIQKbLvFEi2asyquh1WA6nzi6TJa6clFEK'
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
require(twitteR)
require(RCurl)
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
load("C:/Users/Sudip P/Downloads/RDataMining-Tweets-20160203.rdata")
df <- do.call("rbind", lapply(rdmTweets, as.data.frame))
df <- do.call("rbind", lapply(C:/Users/Sudip P/Downloads/RDataMining-Tweets-20160203.rdata, as.data.frame))
df <- do.call("rbind", lapply("C:/Users/Sudip P/Downloads/RDataMining-Tweets-20160203.rdata", as.data.frame))
dim(df)
library(tm)
myCorpus <- Corpus(VectorSource(df$text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
removeURL <- function(x) gsub("http[[:alnum:]]*", "", x)
myCorpus <- tm_map(myCorpus, removeURL)
myStopwords <- c(stopwords('english'), "available", "via")
myStopwords <- setdiff(myStopwords, c("r", "big"))
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
install.packages("Snowball")
show(myCorpus)
install.packages("mlbench")
install.packages("maxent")
exit
quit
update.packages(ask='graphics',checkBuilt=TRUE)
q()
install.packages("mlbench")
install.packages("shiny")
install.packages("e1071")
load("~/.RData")
install.packages("translate")
install.packages("translateR")
install.packages("SnowballC")
install.packages("wordnet")
install.packages("devtools")
library(rtools)
library(devtools)
find_rtools()
exit
quit
clear()
View(removeURL)
View(removeURL)
matmean <- function(x,remove=TRUE)
{}
matmean <- function(x,remove=TRUE){}
matmean <- function(x,remove=TRUE){
nc<-ncol(x)
print(nc)
for(1:nc){
}
}
}}
setwd("~/R Project Files/Rainfall Predictor using Regression")
import_data()
source("Import data.R")
import_data()
